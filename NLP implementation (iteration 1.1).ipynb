{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22a22be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Callum Michael Allan is wanted for twelve alleged offences including: Possession with intent to supply Class A (heroin), supply Class A (cocaine), possession of cannabis, assaulting an emergency worker, affray and dangerous driving. On 11 June 2019 police raided a house suspected to be used for drugs deals. Allan fled and assaulted two officers who restrained him. He was in possession of 113.29 grams of heroin. Allan was charged and appeared at court in April 2020 where he was given unconditional bail and failed to return.\n"
     ]
    }
   ],
   "source": [
    "# Sentences for NLP analysis:\n",
    "Callum_Michael_ALLAN = \"Callum Michael Allan is wanted for twelve alleged offences including: Possession with intent to supply Class A (heroin), supply Class A (cocaine), possession of cannabis, assaulting an emergency worker, affray and dangerous driving. On 11 June 2019 police raided a house suspected to be used for drugs deals. Allan fled and assaulted two officers who restrained him. He was in possession of 113.29 grams of heroin. Allan was charged and appeared at court in April 2020 where he was given unconditional bail and failed to return.\"\n",
    "\n",
    "text = Callum_Michael_ALLAN\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e42995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information I wish to extarct from data:\n",
    "# [x] 1. Name of the criminal: Callum Michael Allan\n",
    "# [x] 2. Crimes: Possession heroin and cannabis, supply cocaine, assaulting, affray, dangerous driving.\n",
    "# [x] 3. Dates: 11 June 2019, April 2020\n",
    "# [x] 4. What drugs were involved: heroin, cocaine, cannabis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e5d534a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Callum', 'Michael', 'Allan', 'is', 'wanted', 'for', 'twelve', 'alleged', 'offences', 'including', ':', 'Possession', 'with', 'intent', 'to', 'supply', 'Class', 'A', '(', 'heroin', ')', ',', 'supply', 'Class', 'A', '(', 'cocaine', ')', ',', 'possession', 'of', 'cannabis', ',', 'assaulting', 'an', 'emergency', 'worker', ',', 'affray', 'and', 'dangerous', 'driving', '.', 'On', '11', 'June', '2019', 'police', 'raided', 'a', 'house', 'suspected', 'to', 'be', 'used', 'for', 'drugs', 'deals', '.', 'Allan', 'fled', 'and', 'assaulted', 'two', 'officers', 'who', 'restrained', 'him', '.', 'He', 'was', 'in', 'possession', 'of', '113.29', 'grams', 'of', 'heroin', '.', 'Allan', 'was', 'charged', 'and', 'appeared', 'at', 'court', 'in', 'April', '2020', 'where', 'he', 'was', 'given', 'unconditional', 'bail', 'and', 'failed', 'to', 'return', '.']\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing for further analysis: Tokenization\n",
    "\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text_tokenized = word_tokenize(text)\n",
    "\n",
    "print(text_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c851950b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Callum', 'NNP'), ('Michael', 'NNP'), ('Allan', 'NNP'), ('is', 'VBZ'), ('wanted', 'VBN'), ('for', 'IN'), ('twelve', 'NNS'), ('alleged', 'VBN'), ('offences', 'NNS'), ('including', 'VBG'), (':', ':'), ('Possession', 'NN'), ('with', 'IN'), ('intent', 'NN'), ('to', 'TO'), ('supply', 'VB'), ('Class', 'NNP'), ('A', 'NNP'), ('(', '('), ('heroin', 'NN'), (')', ')'), (',', ','), ('supply', 'RB'), ('Class', 'NNP'), ('A', 'NNP'), ('(', '('), ('cocaine', 'NN'), (')', ')'), (',', ','), ('possession', 'NN'), ('of', 'IN'), ('cannabis', 'NN'), (',', ','), ('assaulting', 'VBG'), ('an', 'DT'), ('emergency', 'NN'), ('worker', 'NN'), (',', ','), ('affray', 'NN'), ('and', 'CC'), ('dangerous', 'JJ'), ('driving', 'NN'), ('.', '.'), ('On', 'IN'), ('11', 'CD'), ('June', 'NNP'), ('2019', 'CD'), ('police', 'NN'), ('raided', 'VBD'), ('a', 'DT'), ('house', 'NN'), ('suspected', 'VBN'), ('to', 'TO'), ('be', 'VB'), ('used', 'VBN'), ('for', 'IN'), ('drugs', 'NNS'), ('deals', 'NNS'), ('.', '.'), ('Allan', 'NNP'), ('fled', 'VBD'), ('and', 'CC'), ('assaulted', 'VBD'), ('two', 'CD'), ('officers', 'NNS'), ('who', 'WP'), ('restrained', 'VBD'), ('him', 'PRP'), ('.', '.'), ('He', 'PRP'), ('was', 'VBD'), ('in', 'IN'), ('possession', 'NN'), ('of', 'IN'), ('113.29', 'CD'), ('grams', 'NNS'), ('of', 'IN'), ('heroin', 'NN'), ('.', '.'), ('Allan', 'NNP'), ('was', 'VBD'), ('charged', 'VBN'), ('and', 'CC'), ('appeared', 'VBN'), ('at', 'IN'), ('court', 'NN'), ('in', 'IN'), ('April', 'NNP'), ('2020', 'CD'), ('where', 'WRB'), ('he', 'PRP'), ('was', 'VBD'), ('given', 'VBN'), ('unconditional', 'JJ'), ('bail', 'NN'), ('and', 'CC'), ('failed', 'VBD'), ('to', 'TO'), ('return', 'VB'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing for further analysis: Parts of Speech Tagging\n",
    "\n",
    "text_tagged = nltk.pos_tag(text_tokenized)\n",
    "\n",
    "print(text_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27c63d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Possession', 'NN'), ('intent', 'NN'), ('heroin', 'NN'), ('cocaine', 'NN'), ('possession', 'NN'), ('cannabis', 'NN'), ('emergency', 'NN'), ('worker', 'NN'), ('affray', 'NN'), ('driving', 'NN'), ('police', 'NN'), ('house', 'NN'), ('possession', 'NN'), ('heroin', 'NN'), ('court', 'NN'), ('bail', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# Extracting nouns\n",
    "\n",
    "# Keywords appear in text as nouns. So, now I want to extract all the nouns 'NN'\n",
    "# so all the tuples, where the second element is 'NN'\n",
    "\n",
    "def onlyNouns(x):\n",
    "  if x[1] == 'NN':\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "text_nouns = filter(onlyNouns, text_tagged)\n",
    "\n",
    "print(list(text_nouns))\n",
    "# sweet!\n",
    "\n",
    "# now, we can create dictionaries for common crimes and drugs and search the below for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c2ff46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assault\n"
     ]
    }
   ],
   "source": [
    "# issue: some crimes were lost, since they appear not as nouns but as verbs in the text e.g. assaulting \n",
    "# need to normalize the text and extract nouns from it again\n",
    "\n",
    "# Preprocessing for further analysis: Stemming\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "print(wnl.lemmatize('assaulted', 'v')) # valid options are “n” for nouns, “v” for verbs, “a” for adjectives, “r” for adverbs and “s” for satellite adjectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1bca408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Callum', 'NNP'), ('Michael', 'NNP'), ('Allan', 'NNP'), ('is', 'VBZ'), ('wanted', 'VBN'), ('for', 'IN'), ('twelve', 'NNS'), ('alleged', 'VBN'), ('offences', 'NNS'), ('including', 'VBG'), (':', ':'), ('Possession', 'NN'), ('with', 'IN'), ('intent', 'NN'), ('to', 'TO'), ('supply', 'VB'), ('Class', 'NNP'), ('A', 'NNP'), ('(', '('), ('heroin', 'NN'), (')', ')'), (',', ','), ('supply', 'RB'), ('Class', 'NNP'), ('A', 'NNP'), ('(', '('), ('cocaine', 'NN'), (')', ')'), (',', ','), ('possession', 'NN'), ('of', 'IN'), ('cannabis', 'NN'), (',', ','), ('assaulting', 'VBG'), ('an', 'DT'), ('emergency', 'NN'), ('worker', 'NN'), (',', ','), ('affray', 'NN'), ('and', 'CC'), ('dangerous', 'JJ'), ('driving', 'NN'), ('.', '.'), ('On', 'IN'), ('11', 'CD'), ('June', 'NNP'), ('2019', 'CD'), ('police', 'NN'), ('raided', 'VBD'), ('a', 'DT'), ('house', 'NN'), ('suspected', 'VBN'), ('to', 'TO'), ('be', 'VB'), ('used', 'VBN'), ('for', 'IN'), ('drugs', 'NNS'), ('deals', 'NNS'), ('.', '.'), ('Allan', 'NNP'), ('fled', 'VBD'), ('and', 'CC'), ('assaulted', 'VBD'), ('two', 'CD'), ('officers', 'NNS'), ('who', 'WP'), ('restrained', 'VBD'), ('him', 'PRP'), ('.', '.'), ('He', 'PRP'), ('was', 'VBD'), ('in', 'IN'), ('possession', 'NN'), ('of', 'IN'), ('113.29', 'CD'), ('grams', 'NNS'), ('of', 'IN'), ('heroin', 'NN'), ('.', '.'), ('Allan', 'NNP'), ('was', 'VBD'), ('charged', 'VBN'), ('and', 'CC'), ('appeared', 'VBN'), ('at', 'IN'), ('court', 'NN'), ('in', 'IN'), ('April', 'NNP'), ('2020', 'CD'), ('where', 'WRB'), ('he', 'PRP'), ('was', 'VBD'), ('given', 'VBN'), ('unconditional', 'JJ'), ('bail', 'NN'), ('and', 'CC'), ('failed', 'VBD'), ('to', 'TO'), ('return', 'VB'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(text_tagged)\n",
    "# verbs are of multiple types, they start with the letter \"V\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f15b596a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('is', 'VBZ'), ('wanted', 'VBN'), ('alleged', 'VBN'), ('including', 'VBG'), ('supply', 'VB'), ('assaulting', 'VBG'), ('raided', 'VBD'), ('suspected', 'VBN'), ('be', 'VB'), ('used', 'VBN'), ('fled', 'VBD'), ('assaulted', 'VBD'), ('restrained', 'VBD'), ('was', 'VBD'), ('was', 'VBD'), ('charged', 'VBN'), ('appeared', 'VBN'), ('was', 'VBD'), ('given', 'VBN'), ('failed', 'VBD'), ('return', 'VB')]\n"
     ]
    }
   ],
   "source": [
    "# need to filter for all types of verbs\n",
    "\n",
    "def onlyVerbs(x):\n",
    "  if x[1].startswith(\"V\"):\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "text_verbs = filter(onlyVerbs, text_tagged)\n",
    "\n",
    "print(list(text_verbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e9012f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['be', 'want', 'allege', 'include', 'supply', 'assault', 'raid', 'suspect', 'be', 'use', 'flee', 'assault', 'restrain', 'be', 'be', 'charge', 'appear', 'be', 'give', 'fail', 'return']\n"
     ]
    }
   ],
   "source": [
    "# some crimes were lost, since they appear not as nouns but as verbs in the text e.g. assaulting \n",
    "# need to normalize the text and extract nouns from it again\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# getting the only-verbs list again because for some strange reason not accesible from cell above\n",
    "def onlyVerbs(x):\n",
    "  if x[1].startswith(\"V\"):\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "text_verbs = filter(onlyVerbs, text_tagged)\n",
    "\n",
    "# cool, now need to apply WordNetLemmatizer() on all verbs\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "# print(wnl.lemmatize('assaulted', 'v')) # valid options are “n” for nouns, “v” for verbs, “a” for adjectives, “r” for adverbs and “s” for satellite adjectives.\n",
    "\n",
    "def wordLem(x):\n",
    "    return wnl.lemmatize(x[0], 'v')\n",
    "\n",
    "text_lemmed = map(wordLem, text_verbs)\n",
    "\n",
    "print(list(text_lemmed))\n",
    "\n",
    "# important keywords are: supply, assault\n",
    "# we could create a list of crime-related keyowrds and search for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a6a32921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Michael Allan', 'PERSON'),\n",
      " ('twelve', 'CARDINAL'),\n",
      " ('11 June 2019', 'DATE'),\n",
      " ('two', 'CARDINAL'),\n",
      " ('113.29 grams', 'QUANTITY'),\n",
      " ('April 2020', 'DATE')]\n"
     ]
    }
   ],
   "source": [
    "# next task is to extract the name of a criminal from the text that is: Callum Michael Allan\n",
    "\n",
    "# Named Entity Recognition from nltk sucks, so trying out spacy\n",
    "\n",
    "import spacy\n",
    "from pprint import pprint\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(text)\n",
    "pprint([(X.text, X.label_) for X in doc.ents])\n",
    "# fuck yeah!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9456d58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michael Allan\n"
     ]
    }
   ],
   "source": [
    "# now obtaining the person\n",
    "\n",
    "def onlyPerson(x):\n",
    "  if x[1] == 'PERSON':\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "   \n",
    "person_f = filter(onlyPerson, [(X.text, X.label_) for X in doc.ents])\n",
    "\n",
    "person = list(person_f)[0][0]\n",
    "\n",
    "print(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1e9b2e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('11 June 2019', 'DATE'), ('April 2020', 'DATE')]\n"
     ]
    }
   ],
   "source": [
    "# now getting the dates of events\n",
    "\n",
    "def onlyDate(x):\n",
    "  if x[1] == 'DATE':\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "date_f = filter(onlyDate, [(X.text, X.label_) for X in doc.ents])\n",
    "\n",
    "date = list(date_f)\n",
    "\n",
    "print(date)\n",
    "# sometimes you will find more than 1 date of events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116e1f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the end, thanks for listening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a81f3ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
